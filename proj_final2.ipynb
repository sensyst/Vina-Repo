{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish high speed rail system ticket pricing\n",
    "## Inspiration\n",
    "The Guru and Team, have in mind a data product that takes advantage of this data to allow users getting better prices when buying train tickets.\n",
    "\n",
    "We wanted to share the development of this product openly from the very beginning, from data collection to web development. As Data Scientists we understand the importance of getting feedback and ideas from other fellows. \n",
    "\n",
    "## Title\n",
    "\n",
    "    \n",
    "## Sources\n",
    "- [Kaggle ?? competition](kaggle.com/thegurus/spanish-high-speed-rail-system-ticket-pricing)\n",
    "- Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spain](./data/rail_route.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly_express as px\n",
    "import datetime as dt \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note for linting the code\n",
    "\n",
    "```\n",
    "# lint\n",
    "conda install flake8\n",
    "conda install pycodestyle\n",
    "pip install pycodestyle_magic\n",
    "```\n",
    "\n",
    "## In Jupyter\n",
    "### To load\n",
    "```\n",
    "%load_ext pycodestyle_magic\n",
    "```\n",
    "\n",
    "### To run\n",
    "```\n",
    "%%flake8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the source dataset, CSV file\n",
    "# located under the capstone project data folder\n",
    "\n",
    "# loading renfe data into the DataFrame\n",
    "df = pd.read_csv(\n",
    "    './data/renfe.csv',\n",
    "    parse_dates=['insert_date', 'start_date', 'end_date'],nrows = 250000)\n",
    "# df = pd.read_csv('..//Capstone Projects/data/renfe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset size Rows and Columns\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature datatype and number of observations\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column 'unnamed' not used\n",
    "df.drop(columns=\"Unnamed: 0\",inplace = True)\n",
    "\n",
    "df_final = df[df['price'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearranging columns, Price feature is the target variable\n",
    "cols = ['insert_date', 'origin', 'destination',\n",
    "        'start_date', 'end_date', 'train_type', 'train_class',\n",
    "        'fare', 'price']\n",
    "df = df[cols]\n",
    "\n",
    "# final prediction dataframe\n",
    "df_final = df_final[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print(df[df['train_class'] == 'Cama G. Clase'].head(1))\n",
    "\n",
    "#print(df[(df['train_type'] == 'R. EXPRES')].head(1))\n",
    "\n",
    "cond = df.train_class == 'Cama G. Clase'\n",
    "rows = df.loc[cond, :]\n",
    "df_final = df_final.append(rows, ignore_index=True)\n",
    "\n",
    "\n",
    "cond = df.train_class == 'Cama Turista'\n",
    "rows = df.loc[cond, :]\n",
    "df_final = df_final.append(rows, ignore_index=True)\n",
    "\n",
    "cond = df.train_type == 'R. EXPRES'\n",
    "rows = df.loc[cond, :]\n",
    "df_final = df_final.append(rows, ignore_index=True)\n",
    "\n",
    "\n",
    "cond = df.fare == 'Adulto ida'\n",
    "rows = df.loc[cond, :]\n",
    "df_final = df_final.append(rows, ignore_index=True)\n",
    "\n",
    "\n",
    "print(df.train_class.unique())\n",
    "print(df_final.train_class.unique())\n",
    "print(\"--------------------\")\n",
    "print(df.train_type.unique())\n",
    "print(df_final.train_type.unique())\n",
    "print(\"--------------------\")\n",
    "print(df.fare.unique())\n",
    "print(df_final.fare.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns containing null values\n",
    "null_columns = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "# missing values count for each columns\n",
    "print(df[null_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns containing null values in df_final\n",
    "null_columns = df_final.columns[df_final.isnull().any()].tolist()\n",
    "\n",
    "# missing values count for each columns in df_final dataframe used for predict\n",
    "print(df_final[null_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the nan values in df dataframe and see anymore nan values in dataset\n",
    "df = df.dropna(axis=0)\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the nan values in df dataframe and see anymore nan values in dataset\n",
    "df_final['train_class'].dropna(axis=0)\n",
    "print(df_final.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the values in the price column are modified to remove special chars and space\n",
    "df.fare.unique()\n",
    "\n",
    "df_final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data containing spaces and special chars\n",
    "\n",
    "df['fare'].replace(\n",
    "    to_replace=['Promo +'],\n",
    "    value='Promo-Plus',\n",
    "    inplace=True\n",
    ")\n",
    "df['fare'].replace(\n",
    "    to_replace=['Adulto ida'],\n",
    "    value='Adulto-ida',\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# cleaning the data containing spaces and special chars for final \n",
    "# dataframe used for predict\n",
    "df_final['fare'].replace(\n",
    "    to_replace=['Promo +'],\n",
    "    value='Promo-Plus',\n",
    "    inplace=True\n",
    ")\n",
    "df_final['fare'].replace(\n",
    "    to_replace=['Adulto ida'],\n",
    "    value='Adulto-ida',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the values in the train_type column are modified to remove special chars and space\n",
    "df.train_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['train_type'].replace(\n",
    "    to_replace=['AV City'],\n",
    "    value='AV-City',\n",
    "    inplace=True\n",
    ")\n",
    "df['train_type'].replace(\n",
    "    to_replace=['R. EXPRES'],\n",
    "    value='R-EXPRES',\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df_final['train_type'].replace(\n",
    "    to_replace=['AV City'],\n",
    "    value='AV-City',\n",
    "    inplace=True\n",
    ")\n",
    "df_final['train_type'].replace(\n",
    "    to_replace=['R. EXPRES'],\n",
    "    value='R-EXPRES',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the values in the train_class column are modified to remove special chars and space\n",
    "\n",
    "df['train_class'].replace(\n",
    "    to_replace=['Turista con enlace'],\n",
    "    value='Turista-con-enlace',\n",
    "    inplace=True\n",
    ")\n",
    "df['train_class'].replace(\n",
    "    to_replace=['Turista Plus'],\n",
    "    value='Turista-Plus',\n",
    "    inplace=True\n",
    ")\n",
    "df['train_class'].replace(\n",
    "    to_replace=['Cama G. Clase'],\n",
    "    value='Cama-G-Clase',\n",
    "    inplace=True\n",
    ")\n",
    "df['train_class'].replace(\n",
    "    to_replace=['Cama Turista'],\n",
    "    value='Cama-Turista',\n",
    "    inplace=True\n",
    ")\n",
    "df.train_class.unique()\n",
    "\n",
    "df_final['train_class'].replace(\n",
    "    to_replace=['Turista con enlace'],\n",
    "    value='Turista-con-enlace',\n",
    "    inplace=True\n",
    ")\n",
    "df_final['train_class'].replace(\n",
    "    to_replace=['Turista Plus'],\n",
    "    value='Turista-Plus',\n",
    "    inplace=True\n",
    ")\n",
    "df_final['train_class'].replace(\n",
    "    to_replace=['Cama G. Clase'],\n",
    "    value='Cama-G-Clase',\n",
    "    inplace=True\n",
    ")\n",
    "df_final['train_class'].replace(\n",
    "    to_replace=['Cama Turista'],\n",
    "    value='Cama-Turista',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date time values into\n",
    "cols = ['insert_date', 'start_date', 'end_date']\n",
    "for col in cols:\n",
    "    col_name = col.split('_')[0]\n",
    "    df[col_name + '_hour'] = df[col].dt.hour\n",
    "    df[col_name + '_minute'] = df[col].dt.minute\n",
    "    df[col_name + '_weekday'] = df[col].dt.dayofweek  # consider class/label instead\n",
    "    df[col_name + '_day'] = df[col].dt.day\n",
    "    df[col_name + '_month'] = df[col].dt.month\n",
    "    df_final[col_name + '_hour'] = df_final[col].dt.hour\n",
    "    df_final[col_name + '_minute'] = df_final[col].dt.minute\n",
    "    df_final[col_name + '_weekday'] = df_final[col].dt.dayofweek  # consider class/label instead\n",
    "    df_final[col_name + '_day'] = df_final[col].dt.day\n",
    "    df_final[col_name + '_month'] = df_final[col].dt.month\n",
    "   # df[col_name + '_year'] = df[col].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the duration from origin to destination e.g. BARCELONA-MADRID\n",
    "df['duration_hrs'] = df['end_date'] - df['start_date']\n",
    "df['duration_hrs'] = df['duration_hrs'] / np.timedelta64(1, 'h')\n",
    "\n",
    "# determining the duration from origin to destination e.g. BARCELONA-MADRID\n",
    "df_final['duration_hrs'] = df_final['end_date'] - df_final['start_date']\n",
    "df_final['duration_hrs'] = df_final['duration_hrs'] / np.timedelta64(1, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days'] = df['end_day'] - df['start_day']  \n",
    "df_final['days'] = df_final['end_day'] - df_final['start_day']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df[df['days']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Journey duration info between different routes\n",
    "df['duration_hrs'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price info\n",
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total numbers of the days the observation exists\n",
    "total_days = max(df['end_date']) - min(df['start_date'])\n",
    "print(\"total number days in the observations :\", total_days)\n",
    "print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new feature route is generated from the orign and destination input features\n",
    "df['route'] = df.apply(lambda row: \n",
    "                       '%s-%s' % (row['origin'], row['destination']),\n",
    "                       axis=1)\n",
    "df['route'].value_counts()\n",
    "\n",
    "# Repeating the steps to keep final dataframe consistent input features\n",
    "df_final['route'] = df_final.apply(lambda row: \n",
    "                       '%s-%s' % (row['origin'], row['destination']),\n",
    "                       axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the distinct routes from the source dataset\n",
    "routes_list = df['route'].unique()\n",
    "print(routes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition to display the min and max date range \n",
    "def minmaxdate(df, col):\n",
    "    return(df[col].min(), df[col].max())\n",
    "\n",
    "# display the min and max date range for date columns\n",
    "print(minmaxdate(df, 'insert_date'))\n",
    "print(minmaxdate(df, 'start_date'))\n",
    "print(minmaxdate(df, 'end_date'))\n",
    "print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ = {'price': ['min', 'max']}\n",
    "df[['route', 'price']].groupby('route').agg(agg_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding min and max price for each of routes\n",
    "print('Route                 Min   Max')\n",
    "for r in routes_list:\n",
    "    print('%-20s %.1f %.1f' % (\n",
    "        r,\n",
    "        min((df[df['route'] == r]).price),\n",
    "        max((df[df['route'] == r]).price)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_date_only'] = df['start_date'].dt.date\n",
    "# print(sd_list_df.route.value_counts())\n",
    "\n",
    "# repeating the step to create new feature start_date_only for final dataframe\n",
    "df_final['start_date_only'] = df_final['start_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['price']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anomalies of longer duration it happened on weekends\n",
    "#px.scatter(df, x=\"duration_hrs\", y=\"start_weekday\", color=\"route\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='price', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.scatterplot(x='price',y='route',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"duration_hrs\", y=\"train_class\", color=\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"route\", y=\"price\", color=\"fare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"origin\", y=\"destination\", color=\"price\")\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'origin', 'destination', 'train_type', 'train_class',\n",
    "    'fare', 'route', 'insert_hour', 'insert_minute',\n",
    "    'insert_weekday', 'insert_day', 'insert_month',\n",
    "    'insert_year', 'start_hour', 'start_minute',\n",
    "    'start_weekday', 'start_day', 'start_month',\n",
    "    'start_year', 'end_hour', 'end_minute',\n",
    "    'end_weekday', 'end_day', 'end_month', 'end_year']\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\n",
    "    'origin', 'destination', 'train_type','train_class',\n",
    "    'fare', 'route', 'start_weekday',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.get_dummies(df_final, columns=[\n",
    "    'origin', 'destination', 'train_type', 'train_class',\n",
    "    'fare', 'route', 'start_weekday',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['insert_date', 'start_date', 'end_date'])\n",
    "\n",
    "\n",
    "# repeat the unused feature after the date value trnasformation into granual level\n",
    "df_final = df_final.drop(columns=['insert_date', 'start_date', 'end_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['start_date_only','end_weekday','insert_weekday'], axis=1)\n",
    "# print(df.info())\n",
    "\n",
    "df_final = df_final.drop(columns=['start_date_only','end_weekday','insert_weekday'], axis=1)\n",
    "# print(df.info())\n",
    "\n",
    "# define the target variable (dependent variable) as y\n",
    "y = df['price']\n",
    "\n",
    "# define the target variable (dependent variable) as y for y pred\n",
    "y_pred = df_final['price']\n",
    "\n",
    "include_cols = [c for c in df.columns if c != 'price']\n",
    "\n",
    "include_Xpredcols = [c for c in df_final.columns if c != 'price']\n",
    "\n",
    "X = df[include_cols]\n",
    "\n",
    "X_pred = df_final[include_Xpredcols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(include_cols)\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag intermediate output\n",
    "\n",
    "show_steps = True   # for testing/debugging\n",
    "show_steps = False  # without showing steps\n",
    "print(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Forward Feature Selection to pick a good model\n",
    "\n",
    "# start with no input variables\n",
    "included = []\n",
    "r2_list = []\n",
    "adjusted_r2_list = []\n",
    "model = LinearRegression()\n",
    "n = X_test.shape[0]\n",
    "\n",
    "for _ in range(X.shape[1]):\n",
    "    # keep track of model and parameters\n",
    "    best = ('', 0, 0)\n",
    "    # list the input variables to be evaluated\n",
    "    excluded = list(set(X.columns) - set(included))\n",
    "    # for each remaining feature to be evaluated\n",
    "    for new_column in excluded:\n",
    "        # fit the model with the Training data\n",
    "        fit = model.fit(X_train[included + [new_column]], y_train)\n",
    "        # calculate the score (R^2 for Regression)\n",
    "        r2 = fit.score(X_train[included + [new_column]], y_train)\n",
    "        # number of features in this model\n",
    "        k = len(included) + 1\n",
    "        # calculate the adjusted R^2\n",
    "        adjusted_r2 = 1 - (((1 - r2) * (n - 1)) / (n - k - 1))\n",
    "\n",
    "        # if model improves\n",
    "        if adjusted_r2 > best[2]:\n",
    "            # record new parameters\n",
    "            best = (new_column, r2, adjusted_r2)\n",
    "    # END for new_column in excluded\n",
    "\n",
    "    r2_list.append(best[1])\n",
    "    adjusted_r2_list.append(best[2])\n",
    "\n",
    "    included.append(best[0])\n",
    "    excluded = list(set(excluded) - set(best[0]))\n",
    "    print('Add %-30s with R^2 = %.4f and adjusted R^2 = %.4f' % (best))\n",
    "\n",
    "print('')\n",
    "print('Resulting features:')\n",
    "print(', '.join(included))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the included feature list\n",
    "type(included)\n",
    "len(included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart both R^2 and Adjusted R^2\n",
    "\n",
    "# define chart size\n",
    "plt.figure(figsize=(10, 5))\n",
    "# plot each metric \n",
    "plt.plot(range(0, len(included)), r2_list, label='$R^2$')\n",
    "plt.plot(range(0, len(included)), adjusted_r2_list, label='$Adjusted \\: R^2$')\n",
    "# add some better visualisation\n",
    "plt.xlabel('Number of Features')\n",
    "plt.legend()\n",
    "# output the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_A = df.columns[:38]\n",
    "cols_B = df.columns[38:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Ridge Regression model\n",
    "\n",
    "# create a model object to hold the modelling parameters\n",
    "clf = Ridge()\n",
    "\n",
    "# keep track of the intermediate results for coefficients and errors\n",
    "coefs = []\n",
    "errors = []\n",
    "\n",
    "# create a range of alphas to calculate\n",
    "alphas = np.logspace(-6, 6, 200)\n",
    "\n",
    "# Train the model with different regularisation strengths\n",
    "for a in alphas:\n",
    "    clf.set_params(alpha = a)\n",
    "    clf.fit(X, y)\n",
    "    coefs.append(clf.coef_)\n",
    "    errors.append(mean_squared_error(clf.coef_, fit.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "plt.figure(figsize = (20, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularisation')\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.subplot(122)\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, errors)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('error')\n",
    "plt.title('Coefficient error as a function of the regularisation')\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[included[:33]].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Pearson Correlation of Features', size=15)\n",
    "sns.heatmap(df[included[:32]].corr(),\n",
    "            linewidths=0.1,\n",
    "            vmax=1.0,\n",
    "            square=True,\n",
    "            cmap=colormap,\n",
    "            linecolor='white',\n",
    "            annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = df.iloc[:,0:64]  #independent columns\n",
    "y = df.iloc[:,-1]    #target column i.e price range\n",
    "#get correlations of each features in dataset\n",
    "corrmat = df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(200,200))\n",
    "#plot heat map\n",
    "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Train Score:\", train_score)\n",
    "print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_pred.info())\n",
    "y_pred = model.predict(X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['y_hats'] = y_pred \n",
    "df_out = pd.merge(df_final,df_final[['y_hats']],how = 'left',left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_out.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.describe()\n",
    "\n",
    "df_out.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
